{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8e4a07f",
   "metadata": {},
   "source": [
    "# Soil Moisture Prediction with XGBoost and Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08803f53",
   "metadata": {},
   "source": [
    "## Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f540f5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6032817",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c807a3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load and preprocess data\n",
    "df = pd.read_excel('data.xlsx')\n",
    "df = df.rename(columns={'Vreme': 'DateTime'})\n",
    "df['DateTime'] = pd.to_datetime(df['DateTime'], dayfirst=True)\n",
    "df.set_index('DateTime', inplace=True)\n",
    "df = df.sort_index()\n",
    "\n",
    "# Combine 'SM1' and 'SM2' into a new 'SM1' and drop unnecessary columns\n",
    "df['SM1'] = df[['SM1', 'SM2']].mean(axis=1)\n",
    "df.drop(columns=['SM2', 'SM3', 'SM4', 'SM5', 'SM6'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cbe2b7",
   "metadata": {},
   "source": [
    "## 2. Time Aggregation and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c0fa931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Aggregate data by date and create time-based features\n",
    "df_daily = df.resample('D').mean().reset_index()\n",
    "df_daily['DateTime'] = pd.to_datetime(df_daily['DateTime'])\n",
    "df_daily = df_daily.set_index('DateTime')\n",
    "\n",
    "# Create time-based features\n",
    "df_daily['weekofyear'] = df_daily.index.isocalendar().week\n",
    "df_daily['dayofyear'] = df_daily.index.dayofyear\n",
    "df_daily['month'] = df_daily.index.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf5c6135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Feature engineering - lagged features, rolling stats, harmonic features\n",
    "# Lagged features using 'AT1'\n",
    "df_daily['AT1_prev_month'] = df_daily['AT1'].shift(30)\n",
    "\n",
    "# Rolling statistics\n",
    "df_daily['rolling_mean_AT1_30d'] = df_daily['AT1'].rolling(window=30).mean()\n",
    "df_daily['rolling_std_AT1_30d'] = df_daily['AT1'].rolling(window=30).std()\n",
    "\n",
    "# Harmonic features\n",
    "df_daily['week_sin'] = np.sin(2 * np.pi * df_daily['weekofyear'] / 52)\n",
    "df_daily['day_sin'] = np.sin(2 * np.pi * df_daily['dayofyear'] / 365)\n",
    "df_daily['month_sin'] = np.sin(2 * np.pi * df_daily['month'] / 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15deecb6",
   "metadata": {},
   "source": [
    "## 3. Advanced Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48a76035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Feature engineering - short-term changes, extreme weather, interactions\n",
    "# Short-term change features\n",
    "df_daily['AT1_diff1'] = df_daily['AT1'].diff(1)\n",
    "df_daily['AT1_diff2'] = df_daily['AT1'].diff(2)\n",
    "df_daily['PP1_diff1'] = df_daily['PP1'].diff(1)\n",
    "df_daily['PP1_diff2'] = df_daily['PP1'].diff(2)\n",
    "df_daily['AH1_diff1'] = df_daily['AH1'].diff(1)\n",
    "df_daily['AH1_diff2'] = df_daily['AH1'].diff(2)\n",
    "\n",
    "# Extreme weather indicators\n",
    "df_daily['AT1_hot_day'] = (df_daily['AT1'] > df_daily['AT1'].quantile(0.95)).astype(int)\n",
    "df_daily['AT1_cold_day'] = (df_daily['AT1'] < df_daily['AT1'].quantile(0.05)).astype(int)\n",
    "df_daily['PP1_extreme_rain'] = (df_daily['PP1'] > df_daily['PP1'].quantile(0.95)).astype(int)\n",
    "df_daily['PP1_dry_day'] = (df_daily['PP1'] < 1).astype(int)  # Alternative threshold\n",
    "\n",
    "# Interaction features\n",
    "df_daily['AT1_AH1_interaction'] = df_daily['AT1'] * df_daily['AH1']\n",
    "df_daily['PP1_seasonal'] = df_daily['PP1'] * df_daily['month_sin']\n",
    "\n",
    "# Momentum-based rolling features\n",
    "df_daily['ewm_AT1_30d'] = df_daily['AT1'].ewm(span=30).mean()\n",
    "df_daily['ewm_PP1_30d'] = df_daily['PP1'].ewm(span=30).mean()\n",
    "\n",
    "df_daily.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173ef66b",
   "metadata": {},
   "source": [
    "## 4. Time Series Decomposition and Spell Duration Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5daeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Seasonal decomposition and dry/wet spell features\n",
    "# Normalize time\n",
    "df_daily['time'] = (df_daily.index - df_daily.index[0]).days\n",
    "df_daily['time_norm'] = df_daily['time'] / df_daily['time'].max()\n",
    "\n",
    "# Perform seasonal decomposition on 'AT1'\n",
    "result = seasonal_decompose(df_daily['AT1'], model='additive', period=365)\n",
    "df_daily['AT1_trend'] = result.trend\n",
    "df_daily['AT1_residual'] = result.resid\n",
    "df_daily.dropna(inplace=True)\n",
    "\n",
    "# Dry/Wet Spell Duration\n",
    "dry_threshold = 1  # Precipitation < 1 mm is considered dry\n",
    "wet_threshold = 1  # Precipitation >= 1 mm is considered wet\n",
    "\n",
    "df_daily['Dry_Spell_Duration'] = 0\n",
    "df_daily['Wet_Spell_Duration'] = 0\n",
    "\n",
    "# Calculate dry spell duration\n",
    "dry_spell = 0\n",
    "for i in range(len(df_daily)):\n",
    "    if df_daily['PP1'].iloc[i] < dry_threshold:\n",
    "        dry_spell += 1\n",
    "    else:\n",
    "        dry_spell = 0\n",
    "    df_daily['Dry_Spell_Duration'].iloc[i] = dry_spell\n",
    "\n",
    "# Calculate wet spell duration\n",
    "wet_spell = 0\n",
    "for i in range(len(df_daily)):\n",
    "    if df_daily['PP1'].iloc[i] >= wet_threshold:\n",
    "        wet_spell += 1\n",
    "    else:\n",
    "        wet_spell = 0\n",
    "    df_daily['Wet_Spell_Duration'].iloc[i] = wet_spell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28df655a",
   "metadata": {},
   "source": [
    "## 5. Final Feature Selection and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d9bca26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Final feature selection and scaling\n",
    "# Final feature selection\n",
    "df_features = df_daily[['time_norm', 'AT1', 'AT1_prev_month', 'rolling_mean_AT1_30d', 'rolling_std_AT1_30d', \n",
    "                        'week_sin', 'day_sin', 'month_sin', 'AT1_trend', 'AT1_residual', 'Dry_Spell_Duration', \n",
    "                        'Wet_Spell_Duration', 'AT1_diff1', 'AT1_diff2', 'PP1_diff1', 'PP1_diff2', 'AH1_diff1', \n",
    "                        'AH1_diff2', 'AT1_hot_day', 'AT1_cold_day', 'PP1_extreme_rain', 'PP1_dry_day', \n",
    "                        'AT1_AH1_interaction', 'PP1_seasonal', 'ewm_AT1_30d', 'ewm_PP1_30d']]\n",
    "\n",
    "# Apply scaling\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(df_features)\n",
    "\n",
    "# Split data\n",
    "split_date = '2019-01-01'\n",
    "train = features_scaled[df_daily.index < split_date]\n",
    "test = features_scaled[df_daily.index >= split_date]\n",
    "y_train = df_daily.loc[df_daily.index < split_date, 'SM1']\n",
    "y_test = df_daily.loc[df_daily.index >= split_date, 'SM1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29eef9eb",
   "metadata": {},
   "source": [
    "## 6. Model Optimization with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5ed1b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Define Optuna objective function\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 5),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.15),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3, 0.7),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 0.7),\n",
    "        'alpha': trial.suggest_float('alpha', 0, 10),\n",
    "        'lambda': trial.suggest_float('lambda', 0, 10),\n",
    "    }\n",
    "    dtrain = xgb.DMatrix(train, label=y_train)\n",
    "    cv_results = xgb.cv(params, dtrain, num_boost_round=params['n_estimators'], nfold=5, early_stopping_rounds=25, metrics=\"rmse\", as_pandas=True, seed=42)\n",
    "    return cv_results['test-rmse-mean'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300c1b86",
   "metadata": {},
   "source": [
    "## 7. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a83c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Model training and optimization\n",
    "# Directory to save models\n",
    "model_dir = 'best_xgboost_model'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Track the best model\n",
    "best_r2 = 0\n",
    "best_model_path = None\n",
    "\n",
    "for i in range(350):\n",
    "    print(f\"Iteration {i+1}/350\")\n",
    "    \n",
    "    # Run Optuna optimization\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=7)\n",
    "    \n",
    "    # Train the model\n",
    "    best_params = study.best_params\n",
    "    dtrain = xgb.DMatrix(train, label=y_train)\n",
    "    dtest = xgb.DMatrix(test, label=y_test)\n",
    "    model = xgb.train(best_params, dtrain, num_boost_round=best_params['n_estimators'], early_stopping_rounds=40, evals=[(dtest, 'eval')])\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred = model.predict(dtrain)\n",
    "    y_test_pred = model.predict(dtest)\n",
    "    \n",
    "    # Evaluation Metrics\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    print(f'Training R2: {r2_train}')\n",
    "    print(f'Testing R2: {r2_test}')\n",
    "    \n",
    "    # Save the model if R-squared is >= 0.8 and better than the previous best\n",
    "    if r2_test >= 0.8 and r2_test > best_r2:\n",
    "        # Delete the previous best model\n",
    "        if best_model_path and os.path.exists(best_model_path):\n",
    "            os.remove(best_model_path)\n",
    "        \n",
    "        # Save the new best model\n",
    "        best_r2 = r2_test\n",
    "        best_model_path = os.path.join(model_dir, f'best_model_r2_{r2_test:.4f}.model')\n",
    "        model.save_model(best_model_path)\n",
    "        print(f\"New best model saved with R2: {r2_test} at {best_model_path}\")\n",
    "\n",
    "print(\"Process completed.\")\n",
    "print(f\"Best R-squared: {best_r2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
